{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941f8c77",
   "metadata": {},
   "source": [
    "# 01 - Data Ingest\n",
    "\n",
    "Curate legacy conversation assets into the cleaned layout, record provenance, and keep quick sanity checks for downstream notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c202a",
   "metadata": {},
   "source": [
    "**Goals**\n",
    "- Map original pickle/CSV assets into `assets/` with clearer names.\n",
    "- Keep notes on shapes/fields so later steps can reuse the data without re-computing.\n",
    "- Provide small helpers to inspect conversation bundles (list-of-DataFrames structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data_io import load_df_list_pickle, flatten_conversation_bundles, describe_bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "ASSETS_RAW = PROJECT_ROOT / 'assets' / 'raw'\n",
    "ASSETS_PROCESSED = PROJECT_ROOT / 'assets' / 'processed'\n",
    "SOURCE_ROOT = PROJECT_ROOT.parent / 'Raja'\n",
    "YOUTUBE_SOURCE = PROJECT_ROOT.parent / 'jp_vs_cn.csv'\n",
    "ASSETS_RAW.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS_RAW, ASSETS_PROCESSED, SOURCE_ROOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2ac58",
   "metadata": {},
   "source": [
    "### Asset manifest\n",
    "Each row captures a source asset, the cleaned target name, and a short note. Copy with `cp` to keep byte-for-byte fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "asset_manifest = [\n",
    "    {\n",
    "        'source': SOURCE_ROOT / 'Convo' / 'combat_df_list_full.pkl',\n",
    "        'target': ASSETS_RAW / 'combat_threads_text_only.pkl',\n",
    "        'description': '6842 dialogue segments; text only (convokit combat extraction).',\n",
    "    },\n",
    "    {\n",
    "        'source': SOURCE_ROOT / 'Convo' / 'combat_df_list.pkl',\n",
    "        'target': ASSETS_RAW / 'combat_threads_with_agu_sample.pkl',\n",
    "        'description': '334 dialogue segments with agu_1 summarization.',\n",
    "    },\n",
    "    {\n",
    "        'source': SOURCE_ROOT / 'Convo' / 'combat_df_list_imms_1_full.pkl',\n",
    "        'target': ASSETS_PROCESSED / 'combat_threads_with_imitation.pkl',\n",
    "        'description': '6842 dialogues with LLM imitation text imm_1 + imm_1_check.',\n",
    "    },\n",
    "    {\n",
    "        'source': SOURCE_ROOT / 'revised_convo' / 'combat_df_list_imms_1_full_perspective.pkl',\n",
    "        'target': ASSETS_PROCESSED / 'combat_threads_with_perspective.pkl',\n",
    "        'description': '6842 dialogues with imitation plus raw Perspective scores.',\n",
    "    },\n",
    "    {\n",
    "        'source': YOUTUBE_SOURCE,\n",
    "        'target': ASSETS_RAW / 'jp_vs_cn_youtube_comments.csv',\n",
    "        'description': 'YouTube comment dataset used in side analysis.',\n",
    "    },\n",
    "]\n",
    "\n",
    "manifest_df = pd.DataFrame(asset_manifest)\n",
    "manifest_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11219ae",
   "metadata": {},
   "source": [
    "### Quick structural checks\n",
    "Use after assets are copied into `assets/` to confirm column layouts and typical shapes. The loaders are defensive: they handle both list-of-DataFrames bundles and flattened lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for row in asset_manifest:\n",
    "    if not row['target'].exists():\n",
    "        continue\n",
    "    bundle = load_df_list_pickle(row['target'])\n",
    "    summary = describe_bundle(bundle)\n",
    "    print(f\"{row['target'].name}: {summary['bundle_len']} conversations\")\n",
    "    print(f\"columns: {summary['columns']}\")\n",
    "    print(f\"example ids: {summary['example_ids']}\")\n",
    "    flattened = flatten_conversation_bundles(bundle)\n",
    "    display(flattened.head())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
