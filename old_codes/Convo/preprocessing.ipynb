{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os, pandas as pd\n",
    "from convokit import Corpus, Speaker, Utterance, Conversation, download\n",
    "\n",
    "path = \"C:/Users/L/.convokit/downloads/\"\n",
    "os.environ['http_proxy'] = 'http://localhost:7890'\n",
    "os.environ['https_proxy'] = 'http://localhost:7890'\n",
    "\n",
    "def load_dfs(corpus):\n",
    "    speakers = corpus.get_speakers_dataframe().drop(columns=['vectors'])\n",
    "    \n",
    "    conversations = corpus.get_conversations_dataframe().drop(columns=['vectors'])\n",
    "    utterances = corpus.get_utterances_dataframe().drop(columns=['vectors'])\n",
    "    # print(type(speakers), type(conversations), type(utterances))\n",
    "    return speakers, conversations, utterances\n",
    "\n",
    "def print_overview(speaker_df, convo_df, utt_df):\n",
    "    print(\"UttDf attributes:\", list(utt_df.columns),'\\n')\n",
    "    print(\"ConvDf attributes:\", list(convo_df.columns),'\\n')\n",
    "    print(\"SpeakerDf attributes:\", list(speaker_df.columns),'\\n')\n",
    "\n",
    "    # print(convo_df.sample(n=2))\n",
    "    print(\"convo:\",convo_df.shape)\n",
    "    # print(speaker_df.sample(n=2))\n",
    "    print(\"speaker:\",speaker_df.shape)\n",
    "    \n",
    "    print(\"utt:\",utt_df.shape)\n",
    "    # print(utt_df.sample(n=2))\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def optimize_dataframe_int(df,col:str):\n",
    "    df[col] = df[col].astype('int32')\n",
    "    return df\n",
    "\n",
    "def check_column_type(df):\n",
    "    r = df.sample(n=1)\n",
    "    for i in df.columns:\n",
    "        print(i, type(r[i].values[0]))"
   ],
   "id": "d56ae3409c7967b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "list1 = ['conversations-gone-awry-cmv-corpus', 'subreddit-ADD', 'subreddit-AmericanPolitics', 'subreddit-Cornell', 'subreddit-NSFW_Social', 'subreddit-POLUG3']\n",
    "for i in list1:\n",
    "    corpus = Corpus(filename=path+i)\n",
    "    # print(corpus)\n",
    "    speakers, conversations, utterances = load_dfs(corpus)\n",
    "    print_overview(speakers, conversations, utterances)\n",
    "    print(\"#############################################\")"
   ],
   "id": "20456d65f63ef1e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corpus = Corpus(filename=path+'conversations-gone-awry-cmv-corpus')\n",
    "speakers, conversations, utterances = load_dfs(corpus)\n",
    "print_overview(speakers, conversations, utterances)\n",
    "check_column_type(utterances)\n",
    "# print(utterances.shape)\n"
   ],
   "id": "3610dd4f5e018d0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "utterances = optimize_dataframe_int(utterances, 'meta.score')\n",
    "utterances = optimize_dataframe_int(utterances, 'timestamp')\n",
    "utterances = optimize_dataframe_int(utterances, 'meta.gilded')\n",
    "utterances = optimize_dataframe_int(utterances,'meta.retrieved_on')\n",
    "\n",
    "# del corpus, speakers, conversations\n",
    "\n",
    "gc.collect()"
   ],
   "id": "3cd28be67f901b4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# 输入文本\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "\n",
    "def handle_txt(text):\n",
    "\n",
    "    # 处理文本\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 分词\n",
    "    tokens = [token.text for token in doc]\n",
    "    print(\"Tokens:\", tokens)\n",
    "    \n",
    "    # 词性标注\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "    \n",
    "    # 命名实体识别\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(\"Entities:\", entities)\n",
    "    \n",
    "    # 依存句法分析\n",
    "    dependencies = [(token.text, token.dep_, token.head.text) for token in doc]\n",
    "    print(\"Dependencies:\", dependencies)\n",
    "\n",
    "    return tokens, pos_tags, entities, dependencies\n",
    "\n",
    "handle_txt(text)\n"
   ],
   "id": "e69b04d6806d378a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "my_list = [ x[1] for x in handle_txt(text)[1]]\n",
    "my_set = set(my_list)\n",
    "for i in my_set:\n",
    "    print(i, my_list.count(i))\n",
    "    \n",
    "def count_pos_tags(text):\n",
    "    token_length = len(handle_txt(text)[0])\n",
    "    if token_length == 0:\n",
    "        return 1, {}\n",
    "    pos_tags = [x[1] for x in handle_txt(text)[1]]\n",
    "    pos_tags.append('PUNCT')  #+1 count\n",
    "    pos_tag_counts = {tag: pos_tags.count(tag) for tag in set(pos_tags)}\n",
    "\n",
    "    return token_length, pos_tag_counts"
   ],
   "id": "23288d45cbf1b60e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utterances['PUNCTRatio'] = utterances['text'].apply(lambda x: float(count_pos_tags(x)[1].get('PUNCT', 0)) / count_pos_tags(x)[0])",
   "id": "e7e9465ac2d42571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_df_pickle(df, path):\n",
    "    df.to_pickle(path)\n",
    "    print(\"Save to\", path)\n",
    "    \n",
    "def load_df_pickle(path):\n",
    "    df = pd.read_pickle(path)\n",
    "    return df\n",
    "\n",
    "# save_df_pickle(utterances, 'utterancesPunR.pkl')"
   ],
   "id": "4a546f6abb80686d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "test = load_df_pickle('utterancesPunR.pkl')\n",
    "print(test.shape)\n",
    "print(test.head())\n",
    "test_trimmed = test[test['meta.score'] > 20]\n",
    "print(test_trimmed.shape)"
   ],
   "id": "cb4bfc807b27c961",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "PUNCTR_scatter = alt.Chart(test).mark_point().encode(\n",
    "    alt.X('meta.score:Q', title='Score'),\n",
    "    alt.Y('PUNCTRatio:Q', title='PUNCT Ratio')\n",
    ").properties(\n",
    "    title='PUNCT Ratio vs. Score'\n",
    ")\n",
    "PUNCTR_scatter.display()"
   ],
   "id": "43b386ac61d29491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_POS_ratios(df):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    df['nlp'] = df['text'].apply(lambda x: nlp[x] if x != '' else {})\n"
   ],
   "id": "1cbc3a099b8b9ef7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def check_empty_text_column(df):\n",
    "    if 'text' in df.columns:\n",
    "        # 使用向量化操作检查\"text\"列中的空字符串\n",
    "        empty_strings = df['text'] == ''\n",
    "        # 输出存在空字符串的行数\n",
    "        empty_count = empty_strings.sum()\n",
    "        print('Exist empty text') if empty_count > 0 else print('No empty text')\n",
    "    else:\n",
    "        raise KeyError(\"DataFrame does not contain a 'text' column\")\n",
    "\n",
    "def clear_empty_utt(utt_df):\n",
    "    print(\"Before:\", utt_df.shape)\n",
    "    non_empty_mask = utt_df['text'] != ''\n",
    "    utt_df = utt_df.loc[non_empty_mask]\n",
    "    print(\"After:\", utt_df.shape)\n",
    "    return utt_df\n",
    "\n",
    "check_empty_text_column(utterances)\n",
    "utt_df = clear_empty_utt(utterances)"
   ],
   "id": "58f831ca5215a702",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_corpus = Corpus.from_pandas(utterances_df=utt_df, speakers_df= speakers, conversations_df=conversations)\n",
    "new_speaker_df, new_convo_df, new_utt_df = load_dfs(new_corpus)\n",
    "print_overview(new_speaker_df, new_convo_df, new_utt_df)"
   ],
   "id": "8724e8afe4751e6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import altair as alt\n",
    "# alt.data_transformers.enable(\"vegafusion\")\n",
    "# utt_df = new_utt_df\n",
    "utt_df = utterances\n",
    "print(utt_df.head())\n",
    "\n",
    "pop_utt_df = utt_df.loc[utt_df['meta.score'] > 20]\n",
    "print(pop_utt_df.shape)\n",
    "print(pop_utt_df.head())\n",
    "\n",
    "scatter_plot = alt.Chart(pop_utt_df).mark_point().encode(\n",
    "    alt.X('meta.score:Q', title='Score'),\n",
    "    alt.Y('meta.score:Q', title='glided')\n",
    ").properties(\n",
    "    title='Message Score Distribution'\n",
    ")\n",
    "\n",
    "scatter_plot.display()"
   ],
   "id": "7c08ed1419fc5e9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pop_utt_df['date'] = pd.to_datetime(pop_utt_df['timestamp'],unit='s')\n",
    "pop_utt_df['year_month_day'] = pop_utt_df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "brush = alt.selection_interval(encodings=['x'])\n",
    "\n",
    "# Create the time distribution chart with improved x-axis and interactivity\n",
    "time_dist = alt.Chart(pop_utt_df).mark_line().encode(\n",
    "    alt.X('year_month_day:T', title='Date', axis=alt.Axis(labelAngle=-45, tickCount='day')),\n",
    "    alt.Y('count()', title='Number of Messages'),\n",
    "    tooltip=['year_month_day:T', 'count()']\n",
    ").properties(\n",
    "    title='Messages Over Time',\n",
    "    width=800\n",
    ").add_params(\n",
    "    brush\n",
    ").interactive()\n",
    "\n",
    "# Display the chart\n",
    "time_dist.display()"
   ],
   "id": "faf705924308a1ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "filtered_df = pop_utt_df[['meta.gilded']]\n",
    "\n",
    "# Create an Altair bar chart\n",
    "bar_chart = alt.Chart(filtered_df).mark_bar().encode(\n",
    "    x='meta.gilded:N',  # Ordinal type for categorical data\n",
    "    y='count():Q',      # Quantitative type for count\n",
    "    tooltip=['meta.gilded:O', 'count():Q']\n",
    ").properties(\n",
    "    title='Count of Messages by Gilded Status'\n",
    ").interactive()  # Add interactivity\n",
    "\n",
    "# Display the chart\n",
    "bar_chart.display()"
   ],
   "id": "4dd50ed1dc3f0ada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "type(pop_utt_df.loc['c89t0pe', 'timestamp'])\n",
    "print(pop_utt_df.loc[:, 'timestamp'])\n"
   ],
   "id": "e52a723e4a0828e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.DataFrame({\n",
    "    'timestamp': [1691118896, 1691205296, 1691291696],\n",
    "    'value': [10, 20, 15]\n",
    "})\n",
    "\n",
    "# 将时间戳转换为 datetime 对象\n",
    "data['date'] = pd.to_datetime(data['timestamp'], unit='s')\n",
    "\n",
    "# 合并年月日为一个字符串列（可选）\n",
    "data['year_month_day'] = data['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 打印转换后的数据\n",
    "print(data)\n",
    "\n",
    "# 创建一个 Altair 图表\n",
    "chart = alt.Chart(data).mark_line().encode(\n",
    "    x='year_month_day:T',  # 使用年月日格式\n",
    "    y='value:Q'\n",
    ").properties(\n",
    "    title='Time Series Data'\n",
    ")\n",
    "\n",
    "# 显示图表\n",
    "chart.display()"
   ],
   "id": "8a0ea21319e60f8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "63edc597f6e9a170",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
