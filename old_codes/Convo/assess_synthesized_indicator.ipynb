{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-13T12:17:14.683300Z",
     "start_time": "2024-08-13T12:17:14.459560Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# 提取和组合值到向量用于 X\n",
    "\n",
    "with open('updated_before_random_forest.pkl', 'rb') as f:\n",
    "    df_list = pickle.load(f)\n",
    "\n",
    "sensitive_dict_imm_1_weighted = {'matter': -1, 'pedophiles': -1, 'pedophile': -1, 'go': -1, 'see': -1, 'date': -1, 'stop': -1, 'attracted': -1, 'gay': -1, 'happened': -1, 'know': -1, 'risk': -1, 'way': -2, 'speech': -3, 'still': -3, 'penis': -3, 'said': -3, 'cum': -3, 'law': -4, 'rape': -5, 'sexual': -6, 'trans': -7}"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T12:17:21.670073Z",
     "start_time": "2024-08-13T12:17:21.370103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# def calculate_word_frequencies(text):\n",
    "#     # Tokenize the text\n",
    "#     doc = nlp(text)\n",
    "#     \n",
    "#     # Extract tokens\n",
    "#     tokens = [token.text for token in doc]\n",
    "#     \n",
    "#     # Count occurrences of each word\n",
    "#     word_counts = Counter(tokens)\n",
    "#     \n",
    "#     # Calculate total number of tokens\n",
    "#     total_tokens = len(tokens)\n",
    "#     \n",
    "#     # Calculate word frequencies\n",
    "#     word_frequencies = {word: count / total_tokens for word, count in word_counts.items()}\n",
    "#     \n",
    "#     return word_frequencies\n",
    "# \n",
    "# # Example usage\n",
    "# text = \"This is a sample text. This text is for testing.\"\n",
    "# frequencies = calculate_word_frequencies(text)\n",
    "# print(frequencies)"
   ],
   "id": "b07a4dc9e1479bda",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T12:17:22.327634Z",
     "start_time": "2024-08-13T12:17:22.323760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_weighted_score(text, sensitive_dict):\n",
    "    # Tokenize the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract tokens\n",
    "    tokens = [token.text for token in doc]\n",
    "    \n",
    "    # Initialize score\n",
    "    score = 0\n",
    "    \n",
    "    # Calculate score\n",
    "    for token in tokens:\n",
    "        if token in sensitive_dict:\n",
    "            score += sensitive_dict[token]\n",
    "            \n",
    "    score/=len(tokens)\n",
    "    \n",
    "    return score"
   ],
   "id": "ade6fa0200b922cd",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T12:18:02.869153Z",
     "start_time": "2024-08-13T12:17:23.221283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for df in df_list:\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        df.at[index, 'sensi_score'] = calculate_weighted_score(text, sensitive_dict_imm_1_weighted)"
   ],
   "id": "53b22b2b68e9533",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T12:18:32.568240Z",
     "start_time": "2024-08-13T12:18:29.910916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectors = []\n",
    "targets = []\n",
    "\n",
    "for df in df_list:\n",
    "    for index, row in df.iterrows():\n",
    "        # print(1)\n",
    "        vector = row['txt_sentiment'] + row['txt_blob'] + [row['conv_pos']] + [row['token_count']] + [row['meta.score']] + [row['sensi_score']]\n",
    "        vectors.append(vector)\n",
    "        \n",
    "        x = (int(row['imm_check']) + int(row['imm_1_check']))\n",
    "        if x==0:\n",
    "            a=1\n",
    "        else:\n",
    "            a=0\n",
    "        targets.append(a)\n",
    "\n",
    "X = np.array(vectors)\n",
    "\n",
    "Y = np.array(targets)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(rf, X, Y, cv=5, scoring=scoring)\n",
    "\n",
    "rf.fit(X, Y)\n",
    "\n",
    "# 获取特征重要性\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "\n",
    "column_labels = [\n",
    "    'pos', 'neg', 'neu', 'compound',\n",
    "    'polarity', 'subjectivity',\n",
    "    'conv_pos', 'token_count', 'score', 'sensi_score'\n",
    "]\n",
    "\n",
    "# 打印特征重要性\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': column_labels,\n",
    "    'importance': feature_importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Print evaluation metrics\n",
    "for metric in scoring.keys():\n",
    "    print(f\"{metric}: {np.mean(cv_results['test_' + metric])}\")"
   ],
   "id": "f75b3a54e8fc2378",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\L\\anaconda3\\envs\\Raja\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\L\\anaconda3\\envs\\Raja\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\L\\anaconda3\\envs\\Raja\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\L\\anaconda3\\envs\\Raja\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\L\\anaconda3\\envs\\Raja\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature  importance\n",
      "9   sensi_score    0.117288\n",
      "7   token_count    0.109433\n",
      "4      polarity    0.108776\n",
      "3      compound    0.106252\n",
      "2           neu    0.105821\n",
      "5  subjectivity    0.105519\n",
      "1           neg    0.097987\n",
      "6      conv_pos    0.097410\n",
      "0           pos    0.084158\n",
      "8         score    0.067355\n",
      "accuracy: 0.9520249418024609\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "roc_auc: 0.5\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T11:50:01.774563Z",
     "start_time": "2024-08-13T11:49:45.776267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "# 定义随机森林的超参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 创建随机森林分类器\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 使用 GridSearchCV 进行超参数搜索\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# 进行超参数搜索\n",
    "grid_search.fit(X, Y)\n",
    "loaded_grid_search = grid_search\n",
    "# 保存计算结果到文件\n",
    "# with open('grid_search_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(grid_search, f)\n",
    "# \n",
    "# # 加载计算结果\n",
    "# with open('grid_search_results.pkl', 'rb') as f:\n",
    "#     loaded_grid_search = pickle.load(f)\n",
    "\n",
    "# 打印最佳结果\n",
    "print(f\"Best parameters found: {loaded_grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {loaded_grid_search.best_score_}\")\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'roc_auc': make_scorer(roc_auc_score, average='macro', multi_class='ovr')\n",
    "}\n",
    "\n",
    "def auto_search(X, Y, grid=param_grid):\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, Y)\n",
    "    \n",
    "    # 提取所有评分指标的结果\n",
    "    cv_results = grid_search.cv_results_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    # 提取最佳参数的所有评分指标\n",
    "    best_index = grid_search.best_index_\n",
    "    best_scores = {metric: cv_results[f'mean_test_{metric}'][best_index] for metric in scoring.keys() if f'mean_test_{metric}' in cv_results}\n",
    "    return grid_search, grid_search.best_params_, grid_search.best_score_,best_scores"
   ],
   "id": "fb06d98c9846be6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best cross-validation score: 0.95228300631859\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T12:06:06.277504Z",
     "start_time": "2024-08-13T12:06:06.269175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def print_dataframe(df):\n",
    "    print(tabulate(df, headers='keys', tablefmt='psql'))"
   ],
   "id": "87048678eac1c50f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T12:15:59.636340Z",
     "start_time": "2024-08-13T12:15:59.573450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "# print_dataframe(combined_df[['text', 'imm_check', 'imm_1_check', 'sensi_score'][0:1]])\n",
    "print(combined_df[['text','imm_check', 'imm_1_check', 'sensi_score']].head(5).values)"
   ],
   "id": "ee5dff4535fb5524",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['&gt;So within our predefined two genders, we have a huge range of variability. Is a \"tomboy\" type woman \"crazy\" for thinking that the hyper feminine stereotype of women is stupid, and that she should be able to do \"manly\" things without being called butch?\\n\\n\\nI never said anything like that. In fact I\\'ve said the opposite. If someone wants to be a tomboy, whatever, go for it. That\\'s individualism. But saying you\\'re a boy because you act manly according to stereotypes when you\\'re factually female is the same as saying you\\'re a different race because you fit racial stereotypes regardless of the fact that you have non of that racial blood. It\\'s gross. '\n",
      "  True True -0.050359712230215826]\n",
      " [\"&gt; But saying you're a boy because you act manly according to stereotypes when you're factually female is the same as saying you're a different race because you fit racial stereotypes regardless of the fact that you have non of that racial blood. It's gross.\\n\\nSaying you're male *has nothing to do with acting manly or stereotypes*. You seem to not understand how being transgendered works and are extrapolating that to everything else. Let me ask you a question: How do you know you're male?\"\n",
      "  True True -0.00980392156862745]\n",
      " [\"Because I have a penis, and balls, and my chromosomes. I can cum. I don't have any extra packages.\"\n",
      "  False False 0.0]\n",
      " ['&gt; Because I have a penis, and balls, and my chromosomes. I can cum.\\n\\nSo, if you lost your penis and/or balls in an accident you would no longer be male? If some accident made it so you could no longer ejaculate, you would no longer be male? \\n\\nSo, someone with a vagina, the secondary sex characteristics we associate with women (breasts, hourglass figure, slender etc,) but who has testes and XY chromosomes would be male simply because of those chromosomes? \\n\\nThose seem like terrible ways to know you\\'re male. Especially because you likely knew you were \"a boy\" long before you understood what chromosomes were or cumming was.'\n",
      "  False True -0.007407407407407408]\n",
      " [\"Like I said a million times before. Exceptions do not change the general rules.\\n\\nAlso, yeah, I knew I was a boy long before I understood all that stuff. You know what? I also knew I was human long before I understood what that really means. It must be nonsense. I'm a chimp now, because I wanna jerk off in public and throw my shit around.  After all, there was a time when humans and chimps were still close enough to have infertile offspring together. That must mean there's not just chimp and human, but we must also include all the in between, even though it's not relevant.\\n\\nJust stop it already.\"\n",
      "  False False -0.05970149253731343]]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "t = \"Because I have a penis, and balls, and my chromosomes. I can cum. I don't have any extra packages.\"\n",
    "\n"
   ],
   "id": "424b40e4d35609cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
