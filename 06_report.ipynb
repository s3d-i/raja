{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cfe2eb",
   "metadata": {},
   "source": [
    "# 06 - Report & Summary\n",
    "Roll up refusal, toxicity, and topic signals into a compact report artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8254ad",
   "metadata": {},
   "source": [
    "**Goals**\n",
    "- Load processed imitation + Perspective bundles (including the more_refuse variant).\n",
    "- Derive refusal using true_rate when available and summarize refusal/toxicity metrics.\n",
    "- Surface topic highlights from migrated LDA assets and persist a lightweight report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca999ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "from typing import Dict, List, Optional, Sequence, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from utils.data_io import load_df_list_pickle, flatten_conversation_bundles, describe_bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cab7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and toggles\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "ASSETS_RAW = PROJECT_ROOT / \"assets\" / \"raw\"\n",
    "ASSETS_PROCESSED = PROJECT_ROOT / \"assets\" / \"processed\"\n",
    "ASSETS_TOPICS = ASSETS_PROCESSED / \"topics\"\n",
    "REPORT_DIR = ASSETS_PROCESSED / \"report\"\n",
    "\n",
    "IMMITATION_PATH = ASSETS_PROCESSED / \"combat_threads_with_imitation.pkl\"\n",
    "PERSPECTIVE_PATH = ASSETS_PROCESSED / \"combat_threads_with_perspective.pkl\"\n",
    "PERSPECTIVE_LIST_PATH = ASSETS_PROCESSED / \"combat_threads_with_perspective_list.pkl\"\n",
    "PERSPECTIVE_MORE_REFUSE_PATH = ASSETS_PROCESSED / \"combat_threads_with_perspective_list_more_refuse_cleaned.pkl\"\n",
    "\n",
    "LDA_TFIDF_REF = ASSETS_TOPICS / \"lda_results_tfidf_ref.pkl\"\n",
    "LDA_TFIDF_ACC = ASSETS_TOPICS / \"lda_results_tfidf_acc.pkl\"\n",
    "LDA_COUNT_REF = ASSETS_TOPICS / \"lda_results_count_ref.pkl\"\n",
    "LDA_COUNT_ACC = ASSETS_TOPICS / \"lda_results_count_acc.pkl\"\n",
    "\n",
    "SOURCE_MODE = \"more_refuse\"  # options: more_refuse, perspective_list, base\n",
    "HIGH_TOXICITY = 0.5  # label a turn as toxic when Perspective TOXICITY >= this\n",
    "REFUSAL_CONVERSATION_THRESHOLD = 0.1  # bucket conversations by refusal share\n",
    "REFUSAL_TRUE_RATE_THRESHOLD = 0.67  # more_refuse bundle marks refusal when true_rate falls below this share\n",
    "\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ASSETS_PROCESSED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea710c",
   "metadata": {},
   "source": [
    "### Asset manifest\n",
    "List primary inputs and migrated topic assets used to generate the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = [\n",
    "    {\n",
    "        'role': 'input',\n",
    "        'path': IMMITATION_PATH,\n",
    "        'note': 'Imitation bundle with imm_1 + imm_1_check (source: Raja/Convo/combat_df_list_imms_1_full.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'input',\n",
    "        'path': PERSPECTIVE_PATH,\n",
    "        'note': 'Imitation + raw Perspective dicts (source: Raja/revised_convo/combat_df_list_imms_1_full_perspective.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'variant_optional',\n",
    "        'path': PERSPECTIVE_LIST_PATH,\n",
    "        'note': 'Perspective list-encoded scores (source: Raja/revised_convo/combat_df_list_imms_1_full_perspective_list.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'variant_optional',\n",
    "        'path': PERSPECTIVE_MORE_REFUSE_PATH,\n",
    "        'note': 'Perspective list + refuse_add/true_rate heuristics (source: Raja/revised_convo/combat_df_list_imms_1_full_perspective_list_moreRefuse_refuseCleaned.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'topics_optional',\n",
    "        'path': LDA_TFIDF_REF,\n",
    "        'note': 'TF-IDF LDA on refusal conversations (migrated from Raja/revised_convo/lda_results_tfidf_ref.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'topics_optional',\n",
    "        'path': LDA_TFIDF_ACC,\n",
    "        'note': 'TF-IDF LDA on acceptance conversations (migrated from Raja/revised_convo/lda_results_tfidf_acc.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'topics_optional',\n",
    "        'path': LDA_COUNT_REF,\n",
    "        'note': 'Count-vector LDA on refusal conversations (migrated from Raja/revised_convo/lda_results_count_ref.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'topics_optional',\n",
    "        'path': LDA_COUNT_ACC,\n",
    "        'note': 'Count-vector LDA on acceptance conversations (migrated from Raja/revised_convo/lda_results_count_acc.pkl).',\n",
    "    },\n",
    "    {\n",
    "        'role': 'output_optional',\n",
    "        'path': REPORT_DIR / f\"report_{SOURCE_MODE}.json\",\n",
    "        'note': 'Summary JSON written by this notebook (metrics + topic highlights).',\n",
    "    },\n",
    "]\n",
    "\n",
    "pd.DataFrame(manifest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9c942",
   "metadata": {},
   "source": [
    "### Load bundle and derive refusal\n",
    "Use true_rate when available (more_refuse) otherwise fallback to imm_1_check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_source(mode: str):\n",
    "    if mode == 'more_refuse' and PERSPECTIVE_MORE_REFUSE_PATH.exists():\n",
    "        return PERSPECTIVE_MORE_REFUSE_PATH\n",
    "    if mode == 'perspective_list' and PERSPECTIVE_LIST_PATH.exists():\n",
    "        return PERSPECTIVE_LIST_PATH\n",
    "    return PERSPECTIVE_PATH\n",
    "\n",
    "def derive_is_refusal(frame: pd.DataFrame, mode: str) -> pd.Series:\n",
    "    if mode == 'more_refuse' and 'true_rate' in frame.columns:\n",
    "        return frame['true_rate'].fillna(0) < REFUSAL_TRUE_RATE_THRESHOLD\n",
    "    return ~frame['imm_1_check'].astype(bool)\n",
    "\n",
    "SOURCE_PATH = resolve_source(SOURCE_MODE)\n",
    "if not SOURCE_PATH.exists():\n",
    "    raise FileNotFoundError(f'Bundle not found: {SOURCE_PATH}')\n",
    "\n",
    "bundle = load_df_list_pickle(SOURCE_PATH)\n",
    "print(f'using source: {SOURCE_PATH.name}')\n",
    "print('bundle summary:', describe_bundle(bundle))\n",
    "\n",
    "flat = flatten_conversation_bundles(bundle)\n",
    "flat['is_refusal'] = derive_is_refusal(flat, SOURCE_MODE)\n",
    "print('rows', len(flat))\n",
    "print('columns', flat.columns.tolist())\n",
    "flat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdff7da",
   "metadata": {},
   "source": [
    "### Expand Perspective scores\n",
    "Normalize Perspective attributes (dict or list) into flat columns for downstream metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSPECTIVE_ATTRIBUTES = [\n",
    "    'AFFINITY_EXPERIMENTAL',\n",
    "    'COMPASSION_EXPERIMENTAL',\n",
    "    'CURIOSITY_EXPERIMENTAL',\n",
    "    'IDENTITY_ATTACK',\n",
    "    'IDENTITY_ATTACK_EXPERIMENTAL',\n",
    "    'INSULT',\n",
    "    'INSULT_EXPERIMENTAL',\n",
    "    'NUANCE_EXPERIMENTAL',\n",
    "    'PERSONAL_STORY_EXPERIMENTAL',\n",
    "    'PROFANITY',\n",
    "    'PROFANITY_EXPERIMENTAL',\n",
    "    'REASONING_EXPERIMENTAL',\n",
    "    'RESPECT_EXPERIMENTAL',\n",
    "    'SEVERE_TOXICITY',\n",
    "    'SEVERE_TOXICITY_EXPERIMENTAL',\n",
    "    'SEXUALLY_EXPLICIT',\n",
    "    'THREAT',\n",
    "    'THREAT_EXPERIMENTAL',\n",
    "    'TOXICITY',\n",
    "    'TOXICITY_EXPERIMENTAL',\n",
    "]\n",
    "\n",
    "def extract_summary_scores(entry: Optional[dict], attributes: Sequence[str] = PERSPECTIVE_ATTRIBUTES) -> Dict[str, Optional[float]]:\n",
    "    scores: Dict[str, Optional[float]] = {}\n",
    "    for attr in attributes:\n",
    "        key = f'persp_{attr.lower()}'\n",
    "        value = None\n",
    "        if isinstance(entry, dict):\n",
    "            value = entry.get(attr, {}).get('summaryScore', {}).get('value')\n",
    "        scores[key] = value\n",
    "    span_end = None\n",
    "    if isinstance(entry, dict):\n",
    "        spans = entry.get(attributes[0], {}).get('spanScores', [])\n",
    "        if spans:\n",
    "            span_end = spans[0].get('end')\n",
    "    scores['persp_span_end'] = span_end\n",
    "    return scores\n",
    "\n",
    "def perspective_row_to_dict(row: pd.Series) -> Dict[str, Optional[float]]:\n",
    "    ls = row.get('perspective_ls')\n",
    "    if isinstance(ls, (list, tuple)) and len(ls) >= len(PERSPECTIVE_ATTRIBUTES) + 1:\n",
    "        scores = {f'persp_{attr.lower()}': val for attr, val in zip(PERSPECTIVE_ATTRIBUTES, ls[1:])}\n",
    "        scores['persp_span_end'] = ls[0]\n",
    "        return scores\n",
    "    return extract_summary_scores(row.get('perspective'))\n",
    "\n",
    "flat_reset = flat.reset_index(drop=True)\n",
    "score_frame = pd.DataFrame(flat_reset.apply(perspective_row_to_dict, axis=1).tolist())\n",
    "analysis_df = pd.concat([flat_reset, score_frame], axis=1)\n",
    "analysis_df['is_toxic'] = analysis_df['persp_toxicity'].fillna(0) >= HIGH_TOXICITY\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40b71f",
   "metadata": {},
   "source": [
    "### Summary metrics\n",
    "Refusal shares and toxicity breakdowns (overall vs refusal vs acceptance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d27eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "refusal_rate = analysis_df['is_refusal'].mean()\n",
    "convo_refusal = analysis_df.groupby('conversation_idx')['is_refusal'].mean()\n",
    "refusal_convo_share = (convo_refusal > REFUSAL_CONVERSATION_THRESHOLD).mean()\n",
    "\n",
    "toxicity_rate = analysis_df['is_toxic'].mean()\n",
    "toxicity_refuse = analysis_df.loc[analysis_df['is_refusal'], 'is_toxic'].mean()\n",
    "toxicity_accept = analysis_df.loc[~analysis_df['is_refusal'], 'is_toxic'].mean()\n",
    "\n",
    "summary_metrics = {\n",
    "    'rows': len(analysis_df),\n",
    "    'refusal_rate': refusal_rate,\n",
    "    'refusal_conversation_share': refusal_convo_share,\n",
    "    'toxicity_rate': toxicity_rate,\n",
    "    'toxicity_rate_refusals': toxicity_refuse,\n",
    "    'toxicity_rate_acceptances': toxicity_accept,\n",
    "}\n",
    "\n",
    "pd.Series(summary_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f45ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = (\n",
    "    analysis_df.sort_values('persp_toxicity', ascending=False)\n",
    "    [['conversation_idx', 'text', 'imm_1', 'is_refusal', 'persp_toxicity']]\n",
    "    .head(5)\n",
    ")\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65975b5",
   "metadata": {},
   "source": [
    "### Topic highlights\n",
    "Load best runs from migrated LDA assets and surface top terms per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53301a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lda_results(path: Path) -> Optional[List[Dict]]:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    with path.open('rb') as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "def choose_best(runs: Optional[List[Dict]]) -> Optional[Dict]:\n",
    "    if not runs:\n",
    "        return None\n",
    "    return max(\n",
    "        runs,\n",
    "        key=lambda r: (\n",
    "            r.get('coherence') if r.get('coherence') is not None else -1,\n",
    "            -(r.get('perplexity') or 0),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def topics_frame(entry: Dict, label: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'topic': range(len(entry.get('topics', []))),\n",
    "            'top_terms': [' '.join(words) for words in entry.get('topics', [])],\n",
    "            'n_topics': entry.get('n_topics'),\n",
    "            'vectorizer': entry.get('vectorizer').__class__.__name__ if entry.get('vectorizer') else None,\n",
    "            'asset': label,\n",
    "        }\n",
    "    )\n",
    "\n",
    "lda_assets = {\n",
    "    'tfidf_ref': LDA_TFIDF_REF,\n",
    "    'tfidf_acc': LDA_TFIDF_ACC,\n",
    "    'count_ref': LDA_COUNT_REF,\n",
    "    'count_acc': LDA_COUNT_ACC,\n",
    "}\n",
    "\n",
    "topic_tables: List[pd.DataFrame] = []\n",
    "best_topics: Dict[str, Dict] = {}\n",
    "for label, path in lda_assets.items():\n",
    "    runs = load_lda_results(path)\n",
    "    best = choose_best(runs)\n",
    "    if best:\n",
    "        topic_tables.append(topics_frame(best, label))\n",
    "        best_topics[label] = {\n",
    "            'n_topics': best.get('n_topics'),\n",
    "            'top_terms': [' '.join(words) for words in best.get('topics', [])],\n",
    "        }\n",
    "\n",
    "pd.concat(topic_tables, ignore_index=True) if topic_tables else 'No topic assets loaded.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040dae84",
   "metadata": {},
   "source": [
    "### Export report snapshot\n",
    "Persist key metrics and topic highlights to assets/processed/report/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b989f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_PATH = REPORT_DIR / f'report_{SOURCE_MODE}.json'\n",
    "report_payload = {\n",
    "    'source_mode': SOURCE_MODE,\n",
    "    'source_path': str(SOURCE_PATH),\n",
    "    'refusal_true_rate_threshold': REFUSAL_TRUE_RATE_THRESHOLD if SOURCE_MODE == 'more_refuse' else None,\n",
    "    'high_toxicity_threshold': HIGH_TOXICITY,\n",
    "    'refusal_conversation_threshold': REFUSAL_CONVERSATION_THRESHOLD,\n",
    "    'metrics': summary_metrics,\n",
    "    'topic_highlights': best_topics,\n",
    "}\n",
    "\n",
    "with REPORT_PATH.open('w') as fp:\n",
    "    json.dump(report_payload, fp, indent=2)\n",
    "\n",
    "REPORT_PATH"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
